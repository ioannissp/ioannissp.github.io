[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ioannis Spanos",
    "section": "",
    "text": "Welcome to my website where I showcase my data science projects and skills!\nI am Ioannis Spanos, an MSc Statistics student at Imperial College London. I created this page in order to present my data science projects and let other people interact with them, be inspired by them and give me their valuable comments for improvement.\nI believe data always have a story to tell, and what’s a better way to tell a story than a website? I hope you enjoy your time here!"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "This is where you will found all my ready projects. Just click on the project you want to view and you will get there! I hope you like them and don’t forget to contact me if you want to make any comments. Have fun!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nData exploration\n\n\nExploratory analysis on the iris data set\n\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeb scraping using rvest\n\n\nApplying web scraping to extract S&P 500 annual returns data\n\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Economist plots\n\n\nPlotting data using the Economist guidelines\n\n\n\nFeb 21, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "listing_projects/snp500rvest.html",
    "href": "listing_projects/snp500rvest.html",
    "title": "Web scraping using rvest",
    "section": "",
    "text": "Acquiring data is an important step in Data Science. Without the required data you cannot finish your project, or more precisely, you cannot even start it. When we study Data Science at university or in an online course we almost always have the data we need ready for us, usually in a nice .csv file. Of course this is not always the case for real-life applications. Especially in the case you want to work on something no one has worked before, you need to find the data for yourself. If you are lucky, someone will have the data ready for you either to download from the web or through an API.\nHowever, there is always the possibility that the data you need is in a website for example presented in a table. That’s a weird situation: you are so close to the data you want, but yet so far. Until now!\nIn this project we will introduce the idea of web scraping to acquire data from a webpage. Specifically, we will use the rvest libary in R to acquire data from a table online. We will apply this to get the annual returns of S&P 500 from slickcharts.com and use them on an application.\nLet’s firstly import the rvest library.\n\nlibrary(rvest)\n\nWebpages are written in html. Rvest provides all the tools we need to read an html page in R. Indeed, it is as easy as reading a .csv file.\n\nhtml &lt;- read_html(\"https://www.slickcharts.com/sp500/returns\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\n\nIf you visit the website you will see that the data we need are in a table. So, in the html code of the website the data will be in a table object. You can check this with right click+“inspect page source” on the website. Rvest provides an easy way to import tables from the web and the best thing is it imports them as tibbles. Let’s see this below.\n\nsandp500&lt;-html %&gt;% \n  html_element(\"table\") %&gt;%\n  html_table()\nhead(sandp500, n=5)\n\n# A tibble: 5 × 2\n   Year `Total Return`\n  &lt;int&gt;          &lt;dbl&gt;\n1  2024           11.8\n2  2023           26.3\n3  2022          -18.1\n4  2021           28.7\n5  2020           18.4\n\n\nThe above tibble has the returns of the S&P 500 for every year since 1926. We should note however, that the S&P 500 was founded in 1957 so all the data before that are not actual S&P 500 returns but S&P 90 returns (the predecessor of S&P 500). Also, since 2024 is not finished yet the return shown is just the return to this day.\nThe above notes are useful for what we are going to do next.\nBelow we will make a simple function to use for our data. Specifically, we are taking inspiration from the following quote from Warren Buffett, one of the most successful investors, who once said about the S&P 500\n\n“In my view, for most people, the best thing to do is to own the S&P 500 index fund.”\n-Warren Buffett\n\nBut is this really true? The S&P 500 is considered one of the most important indices but we want to see how good it is in a span of specific years. For example, how are we going to see how the S&P 500 usually performs within five years? We will have to plot the rolling mean of the returns for five years. We will do this and plot our solution.\nLet’s see how we do this. To begin with, for each year we will compute the rolling mean with the year in the beginning. So we want the year to be an integer. Also, in the edges we want our function to return NA, so we have to create a vector that has NA in the end, as many NAs as the years. For this reason we will use the function below.\n\npad_with_nas&lt;-function(x, n){\n  #vector x\n  #adding n pads in the end\n  padded_x&lt;-rep(NA,(length(x)+n))\n  padded_x[1:(length(x))]=x\n  return(padded_x)\n}\n\nWe try our function below to make sure it does what we want.\n\nx&lt;-c(1,2,3)\npad_with_nas(x,3)\n\n[1]  1  2  3 NA NA NA\n\n\nWe see that we got what we were expecting: our vector x with three NAs in the end.\nLet’s move to the rolling mean function. This function will compute the rolling mean for five years after each year.\n\nrolling_mean&lt;-function(x, years){\n  #we want a numerical vector x\n  stopifnot(is.logical(x) | is.integer(x) | is.double(x) | is.complex(x))\n  stopifnot(length(x) &gt; 0)\n  # and a positive integer years\n  stopifnot(length(years) == 1)\n  stopifnot(years %% 1 == 0)\n  stopifnot(years &gt; 0)\n  \n  #function\n  padded_x&lt;-pad_with_nas(x, years)\n  \n  output&lt;-rep(NA,length(x))\n  \n  for (index in seq_along(x)){\n    indices_in_window&lt;-seq(index,index+years-1, by=1)\n    output[index]=mean(padded_x[indices_in_window])\n    \n  }\n  return(output)\n  \n  \n}\n\nWe will use this function to see how the rolling mean in the S&P 500 is changing every five years. To do this we will use the data that refer to the actual S&P 500, so for years from 1957. Also, since 2024 is not finished yet, we will exclude it. We do these below.\n\nsandp500_cleaned&lt;-sandp500[2:68,]\nhead(sandp500_cleaned, n=5)\n\n# A tibble: 5 × 2\n   Year `Total Return`\n  &lt;int&gt;          &lt;dbl&gt;\n1  2023           26.3\n2  2022          -18.1\n3  2021           28.7\n4  2020           18.4\n5  2019           31.5\n\n\nWe also want to reverse the order in the lines of our S&P 500 tibble so it starts from year 1957 and not 2023. We do this with the dplyr library.\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nsandp500_cleaned_reversed&lt;-sandp500_cleaned %&gt;%\n  arrange(desc(row_number()))\nhead(sandp500_cleaned_reversed, n=5)\n\n# A tibble: 5 × 2\n   Year `Total Return`\n  &lt;int&gt;          &lt;dbl&gt;\n1  1957         -10.8 \n2  1958          43.4 \n3  1959          12.0 \n4  1960           0.47\n5  1961          26.9 \n\n\nNow we import the ggplot2 library to plot the barplots.\n\nlibrary(ggplot2)\n\nWe plot the barplots of the returns for five years.\n\nmeans&lt;-rolling_mean(sandp500_cleaned_reversed$`Total Return`,5)\nmeans_no_na&lt;-means[!is.na(means)]\nyears&lt;-sandp500_cleaned_reversed$Year[!is.na(means)]\n\ndata&lt;-data.frame(name=as.character(years), value=means_no_na)\nggplot(data, aes(x=name, y=value)) + \n  geom_bar(stat = \"identity\")+coord_flip()\n\n\n\n\n\n\n\n\nThis is a simple barplot but it serves our purpose. You can add more things to the barplot to make it prettier using the commands from our previous project (“The Economist”).\nWe indeed see that the S&P 500 averages mostly positive returns within 5 years. Apart from 1970 and 2000, if you buy the S&P 500 and you sell it in 5 years you will make a profit. Of course this is just an insight in the S&P 500 historical data and it should not be considered as investment advice.\nThis is the end of this project. We gave an explanation of web scraping and we applied it to stock market data. We created a nice function to get insights on the data we acquired ourselves online. I hope you enjoyed it!"
  },
  {
    "objectID": "listing_projects/theeconomist.html",
    "href": "listing_projects/theeconomist.html",
    "title": "The Economist plots",
    "section": "",
    "text": "In this project we designed plots for an article published in a scientific magazine. The aim of the article is to present the results of the Survey and Diary of Consumer Choice related to the payment choices of Americans.\nOf course the above survey is very large, but we will focus on the data that would be of interest for the readers of the magazine, who have general knowledge in Finance. Specifically, we will plot the percentage of payments for each payment method, the amount of money in $ spent with each payment method and the percentage of payments using online payment methods for younger people (Gen Y and Z) and for older generations.\nAll the above will be plotted according to “The Economist” style guide, which can be found here.\nTo begin with, let’s import the libraries we will use for our data wrangling and plots.\n\noptions(warn=-1) #to mute any warnings and make our presentation easier for the reader\n\nlibrary(dplyr)\nlibrary(grid)\nlibrary(tidyverse)\nlibrary(gridExtra)\nlibrary(ggplot2)\nlibrary(cowplot)\n\nLet’s start by importing the data. You can download the required data here.\nNote: You need to download the data for the individual level data and transactions level data, and have them in your working directory to run the codes.\n\noptions(warn=-1)\n\nindividual_level_data&lt;-readr::read_csv(file=\"dcpc_2022_indlevel_public_xls.csv\")\ntransaction_level_data&lt;-readr::read_csv(file=\"dcpc_2022_tranlevel_public_xls.csv\")\n\nWe only want to use some columns from these data. From the individual level dataset we want to use the columns related to age, whether the individual has adopted one of the following non-bank online payment (NBOP) methods: Paypal, Zelle, Venmo, other methods and whether the individual has an NBPO account. We clean the dataset by choosing these columns below.\n\nindividual_level_data_cleaned&lt;-individual_level_data %&gt;% select(age, paypal_adopt, zelle_adopt, venmo_adopt, other_nbops_adopt, nbop_acnt_adopt)\nhead(individual_level_data_cleaned, n=5)\n\n# A tibble: 5 × 6\n    age paypal_adopt zelle_adopt venmo_adopt other_nbops_adopt nbop_acnt_adopt\n  &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1    39            1           0           1                 0               1\n2    73            0           0           0                 0               0\n3    61            1           0           0                 0               1\n4    64            0           0           0                 0               0\n5    63            1           0           1                 0               1\n\n\nWe see that we have all the information we wanted.\nWhen it comes to the transaction level dataset we want the information about the payment instrument used, the amount of money transferred with this instrument, if the transaction was a payment and the type of merchant the transaction included. We do this below.\n\ntransaction_level_data_cleaned&lt;-transaction_level_data %&gt;% select(pi, amnt, payment, merch)\nhead(transaction_level_data_cleaned, n=5)\n\n# A tibble: 5 × 4\n     pi  amnt payment merch\n  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1     3  102.       1    12\n2     1  600        1    14\n3     1   10        1    16\n4     4   70        1     1\n5     1   80        1     2\n\n\nAgain, we have included all the required information above. Now we have smaller datasets we will proceed to the plotting. Note that the number in the payment instruments (pi) variable refer to types of payment instruments. To see what each one means see data codebook. The same goes to the merchant (merch) variable.\nWe firstly create the barplot of the number of payments per payment options. This will be a simple barplot without titles or subtitles. We will add everything we need later.\n\noptions(warn=-1)\n\nBLUE &lt;- \"#076fa2\"\nRED &lt;- \"#E3120B\"\nBLACK &lt;- \"#202020\"\nGREY &lt;- \"grey50\"\n\n#create function for the initial barplot\nmake_number_of_each_method_barplot=function(tib){\n  tib_grouped_by_method=tib %&gt;% \n    group_by(pi) %&gt;%\n    summarise(number=length(pi))\n  tib_grouped_by_method=tib_grouped_by_method[-14, ]\n  \n\n  \n  # Basic barplot\n  \n  name=c(\"Multiple payment methods\", \"Cash\", \"Checks\", \"Credit card\", \"Debit card\", \"Prepaid/gift/EBT card\", \"Bank account\", \"Online banking\", \"Money order\", \"Paypal\", \"Account-to-account\", \"Other method\", \"Deduction from income\")\n  value=tib_grouped_by_method$number\n  plt&lt;-ggplot(tib_grouped_by_method)+\n    geom_col(aes(value,name),fill=BLUE, width=0.6)\n  \n  \n  \n  # Determining the grid, removing the ticks, adding labels etc.\n  \n  plt&lt;-plt+\n    scale_x_continuous(\n      limits = c(0, 6500),\n      breaks = seq(0, 6500, by = 1000), \n      expand = c(0, 0), \n      position = \"top\" \n    ) +\n    scale_y_discrete(expand = expansion(add = c(0, 0.5))) +\n    theme(\n      \n      panel.background = element_rect(fill = \"white\"), # white background\n      \n      panel.grid.major.x = element_line(color = \"#A8BAC4\", linewidth= 0.3),\n      \n      axis.ticks.length = unit(0, \"mm\"),\n      \n      axis.title = element_blank(),\n      \n      axis.line.y.left = element_line(color = \"black\"),\n      \n      axis.text.x = element_text(family = \"Econ Sans cnd\", size = 15, colour=\"black\"), # x axis labels\n      \n      axis.text.y = element_text(family = \"Econ Sans cnd\", size = 15, colour=\"black\") # y axis labels\n    )\n\n  \n\n  plt &lt;- plt + \n    labs(title = NULL, subtitle = NULL) +\n    theme(\n      plot.margin = margin(0.15, 0, 0.1, 0.01, \"npc\")\n    )\n  \n  plt\n}\n\nmake_number_of_each_method_barplot(transaction_level_data_cleaned)\n\n\n\n\n\n\n\n\nThe above bar plot follows the style guide of the economist only in what it has to do with the size of the letters, the colour of the bars and the background and the absence of grid. We, of course need to add a title, subtitle, the source of the data in the bottom and the iconic “The Economist” red line on top. We do all these below.\n\noptions(warn=-1)\n\n#the plot\nmake_number_of_each_method_barplot(transaction_level_data_cleaned)\n\n#add annotations\n\ngrid.text(\n  \"Payment choices\", \n  0, \n  0.925,\n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    fontsize = 22,\n    fontface = \"bold\",\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\ngrid.text(\n  \"Number of transactions per payment instrument\", \n  0, \n  0.875,\n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    fontsize = 20,\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\ngrid.lines(\n  x = c(0, 1),\n  y = 1,\n  gp = gpar(col = \"#e5001c\", lwd = 4)\n)\n\ngrid.rect(\n  x = 0,\n  y = 1,\n  width = 0.05,\n  height = 0.025,\n  just = c(\"left\", \"top\"),\n  gp = gpar(fill = \"#e5001c\", lwd = 0)\n)\n\ngrid.text(\n  \"Sources: Survey and Diary of Consumer Payment Choice, Federal Reserve Bank of Atlanta\", \n  x = 0.005, \n  y = 0.06, \n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    col = \"grey50\",\n    fontsize = 16,\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\n\n\n\n\n\n\n\nSimple, isn’t it? Now we move to the barplot with the number of payments per payment method. We want to see if for example some instruments are chosen for more payments but for less money than others. We proceed as above, firstly creating the basic plot.\n\noptions(warn=-1)\n\nmake_money_for_each_method_barplot=function(tib){\n  \n  tib_grouped_by_method=tib %&gt;% \n                   group_by(pi) %&gt;%\n                   summarise(amount=sum(amnt,na.rm=TRUE))\n  tib_grouped_by_method=tib_grouped_by_method[-14,]\n  \n  BLUE &lt;- \"#076fa2\"\n  RED &lt;- \"#E3120B\"\n  BLACK &lt;- \"#202020\"\n  GREY &lt;- \"grey50\"\n  \n  name=c(\"Multiple payment methods\", \"Cash\", \"Checks\", \"Credit card\", \"Debit card\", \"Prepaid/gift/EBT card\", \"Bank account\", \"Online banking\", \"Money order\", \"Paypal\", \"Account-to-account\", \"Other method\", \"Deduction from income\")\n  value=tib_grouped_by_method$amount\n  \n  # Basic barplot\n  plt &lt;- ggplot(tib_grouped_by_method) +\n    geom_col(aes(value, name), fill = BLUE, width = 0.6) \n  \n  # Determining the grid, removing the ticks, adding labels etc.\n  plt &lt;- plt + \n    scale_x_continuous(\n      limits = c(\"0\"=0, \"750k\"=750000),\n      breaks = c(\"0\"=0,\"100k\"=100000,\"200k\"=200000,\"300k\"=300000,\"400k\"=400000,\"500k\"=500000,\"600k\"=600000,\"700k\"=700000), \n      expand = c(0, 0), # The horizontal axis does not extend to either side\n      position = \"top\"  # Labels are located on the top\n    ) +\n    \n    scale_y_discrete(expand = expansion(add = c(0, 0.5))) +\n    theme(\n      \n      panel.background = element_rect(fill = \"white\"), #white background\n      \n      panel.grid.major.x = element_line(color = \"#A8BAC4\", size = 0.3),\n      \n      axis.ticks.length = unit(0, \"mm\"),\n      \n      axis.title = element_blank(),\n      \n      axis.line.y.left = element_line(color = \"black\"),\n      \n      axis.text.y = element_text(family=\"Econ Sans Cnd\", size=16, colour=\"black\"), # y axis labels\n      \n      axis.text.x = element_text(family = \"Econ Sans Cnd\", size = 16, colour=\"black\") # x axis labels\n    )\n  plt &lt;- plt + \n    theme(\n      plot.margin = margin(0.15, 0, 0.1, 0.01, \"npc\")\n    )\n  \n  \n  plt\n  \n}\n\nmake_money_for_each_method_barplot(transaction_level_data_cleaned)\n\n\n\n\n\n\n\n\nAnd then adding the annotations.\n\noptions(warn=-1) #to silent options and make the presentation better\n\n#plot\nmake_money_for_each_method_barplot(transaction_level_data_cleaned)\n\n#adding annotations\ngrid.text(\n  \"Payment choices revisited\", \n  0, \n  0.925,\n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    fontsize = 22,\n    fontface = \"bold\",\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\ngrid.text(\n  \"Total amount of money in $ included in transactions per method\", \n  0, \n  0.875,\n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    fontsize = 20,\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\ngrid.lines(\n  x = c(0, 1),\n  y = 1,\n  gp = gpar(col = \"#e5001c\", lwd = 4)\n)\n\ngrid.rect(\n  x = 0,\n  y = 1,\n  width = 0.05,\n  height = 0.025,\n  just = c(\"left\", \"top\"),\n  gp = gpar(fill = \"#e5001c\", lwd = 0)\n)\n\ngrid.text(\n  \"Sources: Survey and Diary of Consumer Payment Choice, Federal Reserve Bank of Atlanta\", \n  x = 0.005, \n  y = 0.06, \n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    col = \"grey50\",\n    fontsize = 16,\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\n\n\n\n\n\n\n\nThe final barplot we will show is the barplot that shows the difference in the percentage of people who use online payment methods between generations Z and Y and older generations. The reason for this plot is that in the article we discussed above the author wants to see if modern payment methods are more popular among young people or not.\nBefore we make this plot we will add a new column to our individual level dataset. Specifically, we will add a new variable that takes 1 for gens Y and Z and 0 for older generations. This will help us distinguish between these two groups.\nNote: There are various definitions of the generations, however, we will take the one used in the article which is: gen Y and Z are between 18 and 38 years old and older gens are older than 38 years old.\n\noptions(warn=-1)\n\ncreate_gen_dataset=function(tib){ \n  n=length(tib$age)\n  tib$age_group&lt;-rep(0,n)\n  for (i in 1:n){\n    if (tib$age[i]&gt;=18 & tib$age[i]&lt;=38){\n      tib$age_group[i]=1\n    }\n    \n  }\n  return(tib)\n  \n}\n\nindividual_level_data_age_group_cleaned=create_gen_dataset(individual_level_data_cleaned)\nhead(individual_level_data_age_group_cleaned, n=5)\n\n# A tibble: 5 × 7\n    age paypal_adopt zelle_adopt venmo_adopt other_nbops_adopt nbop_acnt_adopt\n  &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;             &lt;dbl&gt;           &lt;dbl&gt;\n1    39            1           0           1                 0               1\n2    73            0           0           0                 0               0\n3    61            1           0           0                 0               1\n4    64            0           0           0                 0               0\n5    63            1           0           1                 0               1\n# ℹ 1 more variable: age_group &lt;dbl&gt;\n\n\n\noptions(warn=-1)\n\nmake_percentage_per_gen_barplot=function(tib){\n  tib&lt;-tib %&gt;% drop_na() # we drop everyone who hasn't given age or if they have adopted nbop\n  n=length(tib$age)\n  \n  \n  tib_grouped_by_age_group&lt;-tib %&gt;%\n    group_by(age_group) %&gt;%\n     summarise(percentage=100*sum(nbop_acnt_adopt)/n)\n  \n  name&lt;-c(\"Older Generations\",\"Gen Y and Z\")\n  value&lt;-tib_grouped_by_age_group$percentage\n  \n  \n  plt &lt;- ggplot(tib_grouped_by_age_group) +\n    geom_col(aes(name, value), fill = BLUE, width = 0.6) \n  \n  plt &lt;- plt + \n    scale_y_continuous(\n      limits = c(0, 50),\n      breaks = seq(0, 50, by = 10), \n      expand = c(0, 0), \n      position = \"right\"  \n    ) +\n     \n    scale_x_discrete(expand = expansion(add = c(0, 0.5))) +\n    theme(\n      \n      panel.background = element_rect(fill = \"white\"), # white background\n      \n      panel.grid.major.y = element_line(color = \"#A8BAC4\", size = 0.3),\n      \n      axis.ticks.length = unit(0, \"mm\"),\n      \n      axis.title = element_blank(),\n      \n      axis.line.x.bottom = element_line(color = \"black\"),\n      \n      axis.text.y = element_text(family = \"Econ Sans Cnd\", size = 16, colour=\"black\"), # y axis labels\n      \n      axis.text.x = element_text(family = \"Econ Sans Cnd\", size = 16, colour=\"black\") # x axis labels\n    )\n  plt &lt;- plt + \n    labs(title = NULL, subtitle = NULL) +\n    theme(\n      plot.margin = margin(0.15, 0, 0.1, 0.01, \"npc\")\n    )\n  plt\n}\n\nmake_percentage_per_gen_barplot(individual_level_data_age_group_cleaned)\n\ngrid.text(\n  \"Are young people more into non-bank online payments?\", \n  0, \n  0.925,\n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    fontsize = 22,\n    fontface = \"bold\",\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\ngrid.text(\n  \"Percentage of people who have adopted a non-payment platform\", \n  0, \n  0.875,\n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    fontsize = 20,\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\ngrid.lines(\n  x = c(0, 1),\n  y = 1,\n  gp = gpar(col = \"#e5001c\", lwd = 4)\n)\n\ngrid.rect(\n  x = 0,\n  y = 1,\n  width = 0.05,\n  height = 0.025,\n  just = c(\"left\", \"top\"),\n  gp = gpar(fill = \"#e5001c\", lwd = 0)\n)\n\ngrid.text(\n  \"Sources: Survey and Diary of Consumer Payment Choice, Federal Reserve Bank of Atlanta\", \n  x = 0.005, \n  y = 0.06, \n  just = c(\"left\", \"bottom\"),\n  gp = gpar(\n    col = \"grey50\",\n    fontsize = 16,\n    fontfamily = \"Econ Sans Cnd\"\n  )\n)\n\n\n\n\n\n\n\n\nWith he above plot the project ends. I hope it gave you an idea of some commands to use when you want to create more stylish plots. We only considered barplots in this project but you can easily generalise this code to other plots, just plot and then use the annotations like we demonstrated above. If you have any comments to make feel free to email me!"
  },
  {
    "objectID": "listing_projects/dataexploration.html",
    "href": "listing_projects/dataexploration.html",
    "title": "Data exploration",
    "section": "",
    "text": "Data exploration is a big part of a Data Science project. It is the beginning of a project, where we try to understand our data and get an idea of the analysis we want to do to answer a specific question.\nA real-life problem usually doesn’t come as in exercises “construct a linear model with \\(y\\) as the response and \\(x_{1}\\) and \\(x_{2}\\) as the covariates”. We need to apply the model we believe is the best both for our problem and the data we have.\nThis makes exploratory analysis an essential part of modelling. However, many people tend to not pay much attention on it. In this project we aim to showcase a complete data exploration and the fitting of a model based on it. We will work with the well known iris data set which is available in R.\nFirstly, let’s import the libraries we will need.\n\nlibrary(readr)\n\nWe will now import the iris data set which is available in R.\n\ndata(iris)\nhead(iris, n=5)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n\n\nNote: Even though is the previous projects we have worked with tibbles, the iris data set is in a data frame. Tibbles are convenient to work with when you have large data and you use the readr::read_csv command. However, they are not suitable for mathematical operations, which is why we will use a data frame in our example where we want to fit a model.\nBefore we do any exploratory analysis we should be aware of the problem we are trying to solve. This is because there are countless exploratory analyses you can implement but this is not the point. We only need the information that is relevant to our question. This is even more important if we are working with large data sets, which is the case in many application.\nThe problem we will try to solve is whether we can predict sepal length of a flower from its sepal width and/or petal length and/or petal width. Also, does the suggested model change for the species of each flower?\nNow we know the question we will try to answer, let’s get a summary of our data set.\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nThe above output tells us a lot. Firstly, it says that we have equal number of each species of flowers. This is really important because this implies that there is no bias towards any species.\nIt also shows some statistical values about the data. For example, for the means of the variables we have:\n\n\n\nVariable\nMean\n\n\n\n\nSepal Length\n5.843\n\n\nSepal Width\n3.057\n\n\nPetal Length\n3.758\n\n\nPetal Width\n1.199\n\n\n\nWe see that the variables’ means are completely different and any comparison should take that into account. We will see the other elements of the summary in the below boxplot\n\nboxplot(iris[,1:4], main=\"Boxplot for each variable\")\n\n\n\n\n\n\n\n\nWe notice again, the difference in the sizes of each variable and also that we don’t have many outliers in the data, only some in sepal width.\nEven tho we can get an idea about the range of the observations for each variable from the boxplot, we will also present the standard deviations of the variables.\n\nprint(sd(iris$Sepal.Length))\nprint(sd(iris$Sepal.Width))\nprint(sd(iris$Petal.Length))\nprint(sd(iris$Petal.Width))\n\n\n\n\nVariable\nStandard Deviation\n\n\n\n\nSepal Length\n0.8280661\n\n\nSepal Width\n0.4358663\n\n\nPetal Length\n1.765298\n\n\nPetal Width\n0.7622377\n\n\n\nAbove we see that the range of the observations we get for each variable differ a lot.\nSince we will compare the impact of each predictor between the different species (setosa, versicolor, virginica) it will be useful to see if there is a difference in the statistical measures of the variables for each species. We see this in the boxplots below.\n\npar(mfrow=c(1,3),mar=c(6,3,2,1)) #to plot all boxplots in the same line\n\nboxplot(iris[1:4][iris$Species==\"setosa\",], main=\"Setosa\", ylim=c(0,8), las=2)\nboxplot(iris[1:4][iris$Species==\"versicolor\",], main=\"Versicolor\", ylim=c(0,8), las=2)\nboxplot(iris[1:4][iris$Species==\"virginica\",], main=\"Virginica\", ylim=c(0,8), las=2)\n\n\n\n\n\n\n\n\nAbove we see there are differences in all the statistical values for each variable per species and particularly in the medians and the ranges.\nSince we want to predict the sepal length, let’s see how the sepal length is distributed with the following histogram.\n\nhist(iris$Sepal.Length, main=\"Histogram of Sepal Length\", xlab=\"Sepal length\")\n\n\n\n\n\n\n\n\nHowever, we saw above that the sepal length has differences based on the species of flowers we are studying. So we would like to see how those differences are reflected in the distribution of sepal length. For this reason we will produce the histograms for each species.\n\npar(mfrow=c(1,3))\nhist(iris$Sepal.Length[iris$Species==\"setosa\"], main=\"Setosa\", xlab=\"Sepal length\")\nhist(iris$Sepal.Length[iris$Species==\"versicolor\"], main=\"Versicolor\", xlab=\"Sepal length\")\nhist(iris$Sepal.Length[iris$Species==\"virginica\"],main=\"Virginica\", xlab=\"Sepal length\")\n\n\n\n\n\n\n\n\nIndeed there are differences in the way sepal length is distributed for every species, for example there are more flowers with large sepal length in the versicolor species than in the setosa and virginica. So this is an indication that we will need three models, each for every species, or better a model with covariates the ones already discussed and additionally \\(\\mathbb{1}_{set}\\) and \\(\\mathbb{1}_{ver}\\) and for setosa and versicolor respectively, while when they are both \\(0\\) we have virginica.\nA good measure of linear relationship between variables is the Pearson correlation. Let’s calculate the Pearson correlation of sepal length with sepal width, petal length and petal width.\n\nprint(cor(iris$Sepal.Length, iris$Sepal.Width))\nprint(cor(iris$Sepal.Length, iris$Petal.Length))\nprint(cor(iris$Sepal.Length, iris$Petal.Width))\n\n\n\n\n\nSepal Width\nPetal Length\nPetal Width\n\n\n\n\nSepal Length\n-0.1175698\n0.8717538\n0.8179411\n\n\n\nWe see above that sepal length has a high linear correlation with petal length and petal width, so the latter seem to be useful predictors for the former. The relationship in both cases is positive. However, when it comes to sepal width we see that it is not highly linearly correlated with sepal length. Many would be quick to say that this means that sepal width is not a good predictor. However, let’s see how the correlation changes with flower species.\n\nprint(cor(iris$Sepal.Length[iris$Species==\"setosa\"], iris$Sepal.Width[iris$Species==\"setosa\"]))\nprint(cor(iris$Sepal.Length[iris$Species==\"versicolor\"], iris$Sepal.Width[iris$Species==\"versicolor\"]))\nprint(cor(iris$Sepal.Length[iris$Species==\"virginica\"], iris$Sepal.Width[iris$Species==\"virginica\"]))\n\n\n\n\nSepal length/Sepal width\nSetosa\nVersicolor\nVirginica\n\n\n\n\nSepal length\n0.7425467\n0.5259107\n0.4572278\n\n\n\nIn this case we see that for the setosa species the correlation between sepal length and sepal width is large. This means that sepal width can be an important predictor for sepal length and should be included in the model. Of course we are gonna confirm this later, but the exploratory analysis so far has given us an idea of the relationship between the variables.\nTo make this relation even easier to understand we will plot pairplots for the data. Also, we will colour each species differently to see how the relationship changes with the species in each case.\n\npairs(iris[,1:4],col=iris[,5],oma=c(6,6,6,12))\npar(xpd=TRUE) #for the colouring\nlegend(0.85, 0.6,as.vector(unique(iris$Species)),fill=c(1,2,3))\n\n\n\n\n\n\n\n\nIn the above plot we see the relationships more clearly. All predictors seem to be significant to predict sepal length and they all have a linear relationship with it, some stronger (petal length and width) and some weaker (sepal width for versicolor and virginica). As we can see, the relationships for each species are different so we want to model it differently. This is why we have reached the full model: \\[\\begin{equation}\nY=\\alpha+\\beta_{1}X_{1}+\\beta_{2}X_{2}+\\beta_{3}X_{3}+\\gamma_{1}\\mathbb{1}_{set}+\\gamma_{2}\\mathbb{1}_{ver},\n\\end{equation}\\] where \\(Y=\\)Sepal Length, \\(X_{1}=\\)Sepal Width, \\(X_{2}=\\)Petal Length and \\(X_{3}=\\)Petal Width. Also \\(\\mathbb{1}_{set}=1\\) for setosa and \\(\\mathbb{1}_{ver}=1\\) for versicolor. When they are both \\(0\\) we have virginica.\nTo fit the model above we firstly need to add to our data frame the variables \\(\\mathbb{1}_{set}, \\mathbb{1}_{ver}\\) and \\(\\mathbb{1}_{vir}\\) that become one only for setosa, versicolor and virginica respectively. We do this below.\n\n#we create variables Setosa, Versicolor\niris$Setosa=rep(0, 150)\niris$Versicolor=rep(0, 150)\n\n#we put 1 where variables become setosa and versicolor respectively\niris$Setosa[which(iris$Species==\"setosa\")]=1\niris$Versicolor[which(iris$Species==\"versicolor\")]=1\nhead(iris, n=5)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species Setosa Versicolor\n1          5.1         3.5          1.4         0.2  setosa      1          0\n2          4.9         3.0          1.4         0.2  setosa      1          0\n3          4.7         3.2          1.3         0.2  setosa      1          0\n4          4.6         3.1          1.5         0.2  setosa      1          0\n5          5.0         3.6          1.4         0.2  setosa      1          0\n\n\nNow we have everything we need to build our model. We fit it below and get its summary.\n\nmodel&lt;-lm(Sepal.Length~Sepal.Width+Petal.Length+Petal.Width+Setosa+Versicolor, data=iris)\nsummary(model)\n\n\nCall:\nlm(formula = Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width + \n    Setosa + Versicolor, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.79424 -0.21874  0.00899  0.20255  0.73103 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   1.14777    0.35356   3.246  0.00145 ** \nSepal.Width   0.49589    0.08607   5.761 4.87e-08 ***\nPetal.Length  0.82924    0.06853  12.101  &lt; 2e-16 ***\nPetal.Width  -0.31516    0.15120  -2.084  0.03889 *  \nSetosa        1.02350    0.33373   3.067  0.00258 ** \nVersicolor    0.29994    0.11898   2.521  0.01280 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3068 on 144 degrees of freedom\nMultiple R-squared:  0.8673,    Adjusted R-squared:  0.8627 \nF-statistic: 188.3 on 5 and 144 DF,  p-value: &lt; 2.2e-16\n\n\nIn the model above we see that all predictors have p-value less than \\(0.05\\) which indicates they are statistically significant as the exploratory analysis had implied. Also, the adjusted \\(R^{2}\\) is \\(86.27\\) which shows the model is a good fit for the data. The fitted model is \\[\\begin{equation}\nY=1.418+0.496X_{1}+0.829X_{2}-0.315X_{3}+1.024\\mathbb{1}_{set}+0.3\\mathbb{1}_{ver}.\n\\end{equation}\\] With the model above we can predict the sepal length from the other variables and answer to any relevant questions about it.\nHere our project ends. The main purpose of the project was to show how an exploratory analysis should be designed and implemented. Of course, there are a lot you can do to explore the data, but we tried to do only what is relevant to the question we had to ask. We then saw how this exploratory analysis helped us to design the appropriate model for our problem.\nI hope you enjoyed the project and got an idea of what exploratory analysis should include. Good luck to your projects!"
  }
]